# Emo-Ensemble
[Competition] [제 2회 ETRI 휴먼이해 인공지능 논문경진대회](https://aifactory.space/competition/qna/2234/1019)  
[Paper] Emo-Ensemble: An Ensemble-based Multimodal Emotion Recognition using wav2vec2 and KoBERT

## Original Data Source
[KEMDy20] [한국어 멀티모달 감정데이터셋 2020](https://nanum.etri.re.kr/share/kjnoh/KEMDy20?lang=ko_KR)  
<img src="https://user-images.githubusercontent.com/113504815/232485081-a0b3e3fe-78b2-42be-ac54-185945990cd7.png" width="600" height="90">  

[AI Hub] [감정 분류를 위한 대화 음성 데이터셋](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100)  
<img src="https://user-images.githubusercontent.com/113504815/232484969-550c167a-f9a6-438e-b08f-ff75a84d7efa.png" width="600" height="150">

## Environment

## Directory (Local)

## Directory (Colab)

## Pretrained Model info

### wav2vec2

### KoBERT

## Benchmark Model info
[MMM: Multi-modal Emotion Recognition in conversation with MLP Mixer](https://github.com/ISDS-Human-Understanding/HumanUnderstandingOpen)

## Emo-Ensemble hyper-parameters

### wav2vec2

### KoBERT

## Model Architecture

## Experiment results

### Fig 1. Class distribution (KEMDy20)
<img src="Class_distribution_origin.png">

### Fig 2. Class distribution (KEMDy20 + AI Hub)
<img src="Class_distribution_add.png">
