{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f56cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d1343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc0fdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"../../KEMDy20_v1_1/Extract/Dataset.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0742d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(dataset[\"train_x\"]).float()\n",
    "test_x = torch.from_numpy(dataset[\"test_x\"]).float()\n",
    "train_aug_x = torch.from_numpy(dataset[\"train_aug_x\"]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1d6138",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = dataset[\"train_y\"]\n",
    "test_y = dataset[\"test_y\"]\n",
    "train_aug_y = dataset[\"train_aug_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d84e8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e4ce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.4733\n",
      "Epoch [2/30], Loss: 1.9926\n",
      "Epoch [3/30], Loss: 0.9184\n",
      "Epoch [4/30], Loss: 0.6841\n",
      "Epoch [5/30], Loss: 0.6169\n",
      "Epoch [6/30], Loss: 0.5645\n",
      "Epoch [7/30], Loss: 0.5370\n",
      "Epoch [8/30], Loss: 0.5222\n",
      "Epoch [9/30], Loss: 0.5085\n",
      "Epoch [10/30], Loss: 0.5006\n",
      "Epoch [11/30], Loss: 0.4921\n",
      "Epoch [12/30], Loss: 0.4854\n",
      "Epoch [13/30], Loss: 0.4806\n",
      "Epoch [14/30], Loss: 0.4761\n",
      "Epoch [15/30], Loss: 0.4728\n",
      "Epoch [16/30], Loss: 0.4677\n",
      "Epoch [17/30], Loss: 0.4647\n",
      "Epoch [18/30], Loss: 0.4606\n",
      "Epoch [19/30], Loss: 0.4566\n",
      "Epoch [20/30], Loss: 0.4541\n",
      "Epoch [21/30], Loss: 0.4506\n",
      "Epoch [22/30], Loss: 0.4480\n",
      "Epoch [23/30], Loss: 0.4450\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder 모델을 정의합니다.\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "    \n",
    "        self.fc1 = nn.Linear(100000, 4096, bias=False)\n",
    "        self.fc2 = nn.Linear(4096, 2048, bias=False)\n",
    "        self.fc3 = nn.Linear(2048, 1024, bias=False)\n",
    "        \n",
    "        self.defc1 = nn.Linear(1024, 2048, bias=False)\n",
    "        self.defc2 = nn.Linear(2048, 4096, bias=False)\n",
    "        self.defc3 = nn.Linear(4096, 100000, bias=False)\n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = self.defc1(x)\n",
    "        x = self.defc2(x)      \n",
    "        x = self.defc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "model = AutoEncoder().to(device)\n",
    "\n",
    "# L1 Loss 함수를 정의합니다.\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# 옵티마이저를 정의합니다.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 하이퍼파라미터를 정의합니다.\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "\n",
    "# 모델을 학습합니다.\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(train_x), batch_size):\n",
    "        batch_x = train_x[i:i+batch_size]\n",
    "        \n",
    "        # 모델에 입력 데이터를 GPU 상으로 이동시킵니다.\n",
    "        batch_x = batch_x.to(device)\n",
    "        \n",
    "        # 순전파 단계를 수행합니다.\n",
    "        output = model(batch_x)\n",
    "        \n",
    "        # 손실을 계산하고 역전파 단계를 수행합니다.\n",
    "        loss = criterion(output, batch_x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # 현재 epoch의 손실을 출력합니다.\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e18dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 Encoder 모델을 추출합니다.\n",
    "encoder_model = nn.Sequential(*list(model.children())[:3])\n",
    "\n",
    "# 배치 사이즈 정의\n",
    "batch_size = 32\n",
    "\n",
    "# train_x를 배치 단위로 분할하고 Autoencoder에 입력하여 feature 추출\n",
    "encoded_train_x_list = []\n",
    "for i in range(0, len(train_x), batch_size):\n",
    "    batch_x = train_x[i:i+batch_size]\n",
    "    encoded_train_x_list.append(model.encoder(batch_x.to(device)).cpu().detach().numpy())\n",
    "encoded_train_x = np.concatenate(encoded_train_x_list, axis=0)\n",
    "\n",
    "# test_x를 배치 단위로 분할하고 Autoencoder에 입력하여 feature 추출\n",
    "encoded_test_x_list = []\n",
    "for i in range(0, len(test_x), batch_size):\n",
    "    batch_x = test_x[i:i+batch_size]\n",
    "    encoded_test_x_list.append(model.encoder(batch_x.to(device)).cpu().detach().numpy())\n",
    "encoded_test_x = np.concatenate(encoded_test_x_list, axis=0)\n",
    "\n",
    "# train_x_aug를 배치 단위로 분할하고 Autoencoder에 입력하여 feature 추출\n",
    "encoded_train_aug_x_list = []\n",
    "for i in range(0, len(train_aug_x), batch_size):\n",
    "    batch_x = train_aug_x[i:i+batch_size]\n",
    "    encoded_train_aug_x_list.append(model.encoder(batch_x.to(device)).cpu().detach().numpy())\n",
    "encoded_train_aug_x = np.concatenate(encoded_train_aug_x_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f7c31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"../../KEMDy20_v1_1/Extract/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd7e1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(save_path+\"Dataset_AE\",\n",
    "         train_x = encoded_train_x,\n",
    "         train_y = train_y,\n",
    "         test_x = encoded_test_x,\n",
    "         test_y = test_y,\n",
    "         train_aug_x = encoded_train_x,\n",
    "         train_aug_y = train_aug_y\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59785a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
