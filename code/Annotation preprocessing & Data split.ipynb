{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c5cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchaudio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67e80e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_folder_path = \"../../KEMDy20_v1_1/wav/\"\n",
    "an_folder_path = \"../../KEMDy20_v1_1/annotation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee48c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_file_paths = []\n",
    "for root, dirs, files in os.walk(wav_folder_path):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        if file_path.endswith(\".wav\"): # .wav 확장자만 저장\n",
    "            wav_file_paths.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d10bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_file_paths = [an_folder_path+i for i in os.listdir(an_folder_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecd9ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_an_file_paths, test_an_file_paths = train_test_split(an_file_paths, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f35c4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(an_file_paths, data_type):\n",
    "    seg_eval_df_list = []\n",
    "    \n",
    "    for an_file_path in an_file_paths:\n",
    "        file = pd.read_csv(an_file_path)\n",
    "        seg_eval = file.iloc[1:].filter(regex=\"^(Segment|Eval)\")\n",
    "        seg_eval_df_list.append(seg_eval)\n",
    "        \n",
    "    seg_eval_df = pd.concat(seg_eval_df_list)\n",
    "    \n",
    "    # 라벨 열(`Eval01F`, `Eval02M`, ...)과 값을 하나의 열로 변환\n",
    "    melted_df = seg_eval_df.melt(id_vars='Segment ID', var_name='Label', value_name='Emotion')\n",
    "\n",
    "    # 각 Segment ID별 라벨 발생 횟수 계산\n",
    "    em_count_df = melted_df.groupby(['Segment ID', 'Emotion'])['Emotion'].count().reset_index(name='Count')\n",
    "    \n",
    "    # pivot_table 함수를 사용하여 각 Segment ID당 happy와 neutral 라벨이 발생한 횟수 계산\n",
    "    label_df = pd.pivot_table(em_count_df, index='Segment ID', columns='Emotion', values='Count', aggfunc=sum, fill_value=0).reset_index()\n",
    "    \n",
    "    # wav에 대한 path를 추가\n",
    "    for wav_file_path in wav_file_paths:\n",
    "        segment_id = wav_file_path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "        row = label_df.loc[label_df[\"Segment ID\"].str.endswith(segment_id)].index\n",
    "        if len(row) > 0:\n",
    "            label_df.loc[row, \"path\"] = wav_file_path\n",
    "    \n",
    "    # 라벨을 확률 값으로 정의\n",
    "    prob_label_df = copy.copy(label_df)\n",
    "    prob_label_df.iloc[:,1:-1] /= 10\n",
    "    prob_label_df[\"emotion\"] = prob_label_df.iloc[:,1:-1].apply(list, axis=1)\n",
    "    prob_label_df = prob_label_df[[\"Segment ID\", \"path\", \"emotion\"]]\n",
    "    \n",
    "    # 라벨을 여러개로 정의\n",
    "    multi_label_df = copy.copy(label_df)\n",
    "    multi_label_df.iloc[:,1:-1] = (multi_label_df.iloc[:,1:-1] > 0).astype(int)\n",
    "    multi_label_df.iloc[:,1:-1] = multi_label_df.iloc[:,1:-1].div(multi_label_df.iloc[:,1:-1].sum(axis=1), axis=0)\n",
    "    multi_label_df.iloc[:,1:-1] = multi_label_df.iloc[:,1:-1].round(5)\n",
    "    multi_label_df[\"emotion\"] = multi_label_df.iloc[:,1:-1].apply(list, axis=1)\n",
    "    multi_label_df = multi_label_df[[\"Segment ID\", \"path\", \"emotion\"]]\n",
    "    \n",
    "    # 데이터 저장\n",
    "    save_path = \"../../KEMDy20_v1_1/Splitting/\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    prob_label_df.to_csv(f\"{save_path}{data_type}_Prob.csv\", encoding=\"utf-8\", index=False)\n",
    "    multi_label_df.to_csv(f\"{save_path}{data_type}_Multi.csv\", encoding=\"utf-8\", index=False)\n",
    "    if not os.path.exists(save_path+\"Label.txt\"):\n",
    "        with open(save_path+\"Label.txt\", \"wb\") as f:\n",
    "            pickle.dump(label_df.columns[1:-1], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e2e4c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yechani\\AppData\\Local\\Temp\\1\\ipykernel_5080\\211264329.py:35: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  multi_label_df.iloc[:,1:-1] = (multi_label_df.iloc[:,1:-1] > 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "preprocessing(train_an_file_paths, \"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20530465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yechani\\AppData\\Local\\Temp\\1\\ipykernel_5080\\211264329.py:35: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  multi_label_df.iloc[:,1:-1] = (multi_label_df.iloc[:,1:-1] > 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "preprocessing(test_an_file_paths, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af16aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../KEMDy20_v1_1/Splitting/Label.txt\", \"rb\") as f:\n",
    "    ttt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bff5b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'], dtype='object', name='Emotion')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea8b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
