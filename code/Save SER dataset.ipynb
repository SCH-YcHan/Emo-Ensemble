{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af59a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torchaudio\n",
    "import librosa\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5816d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": \"../../KEMDy20_v1_1/Splitting/Train.csv\",\n",
    "    \"test\": \"../../KEMDy20_v1_1/Splitting/Test.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e6d1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Yechani/.cache/huggingface/datasets/csv/default-1ac06c035d845d89/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2226412aa4540a1b43f90804a022bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Emotion', 'Path'],\n",
      "    num_rows: 25890\n",
      "})\n",
      "Dataset({\n",
      "    features: ['Emotion', 'Path'],\n",
      "    num_rows: 6312\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files = data_files)\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d22787",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_column = \"Path\"\n",
    "output_column = \"Emotion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590441ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classification problem with 7 classes: ['angry', 'disqust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# we need to distinguish the unique labels in our SER dataset\n",
    "label_list = train_dataset.unique(output_column)\n",
    "label_list.sort()  # Let's sort it for determinism\n",
    "num_labels = len(label_list)\n",
    "print(f\"A classification problem with {num_labels} classes: {label_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a0a0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"kresnik/wav2vec2-large-xlsr-korean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1103cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(model_name_or_path,)\n",
    "target_sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(f\"The target sampling rate: {target_sampling_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad34a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path):\n",
    "    speech_array, sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(sampling_rate, target_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "\n",
    "def label_to_id(label, label_list):\n",
    "\n",
    "    if len(label_list) > 0:\n",
    "        return label_list.index(label) if label in label_list else -1\n",
    "\n",
    "    return label\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    speech_list = [speech_file_to_array_fn(path) for path in examples[input_column]]\n",
    "    target_list = [label_to_id(label, label_list) for label in examples[output_column]]\n",
    "\n",
    "    result = processor(speech_list, sampling_rate=target_sampling_rate)\n",
    "    result[\"labels\"] = list(target_list)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89152f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Yechani\\.cache\\huggingface\\datasets\\csv\\default-1ac06c035d845d89\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-698686685ec51acc.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Yechani\\.cache\\huggingface\\datasets\\csv\\default-1ac06c035d845d89\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-90d7e1f8c5db0ae9.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    preprocess_function,\n",
    "    batch_size=100,\n",
    "    batched=True\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    preprocess_function,\n",
    "    batch_size=100,\n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e168981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb156ac42f0450599138daa71c924f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/39 shards):   0%|          | 0/25890 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33de995415df4f3bb5f439360926a562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/10 shards):   0%|          | 0/6312 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = \"../../KEMDy20_v1_1/Dataset/\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "train_dataset.save_to_disk(save_path+\"train_dataset\")\n",
    "test_dataset.save_to_disk(save_path+\"test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b56eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# 압축할 파일/폴더 경로\n",
    "train_dataset_path = \"../../KEMDy20_v1_1/Dataset/train_dataset\"\n",
    "test_dataset_path = \"../../KEMDy20_v1_1/Dataset/test_dataset\"\n",
    "\n",
    "# 압축된 파일 저장 경로\n",
    "zip_file_path = \"../../KEMDy20_v1_1/Dataset.zip\"\n",
    "\n",
    "# 압축 파일 생성\n",
    "with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # train_dataset 폴더 내부 파일/폴더 추가\n",
    "    for root, dirs, files in os.walk(train_dataset_path):\n",
    "        for file in files:\n",
    "            zipf.write(os.path.join(root, file))\n",
    "\n",
    "    # test_dataset 폴더 내부 파일/폴더 추가\n",
    "    for root, dirs, files in os.walk(test_dataset_path):\n",
    "        for file in files:\n",
    "            zipf.write(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7c7767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
